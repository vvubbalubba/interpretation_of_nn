{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0093d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mimetypes\n",
    "import fnmatch\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from progress.bar import IncrementalBar\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import io\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from datetime import datetime, date, time\n",
    "from PIL import Image\n",
    "import itertools \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.models as models\n",
    "from ViT.models.modeling import VisionTransformer, CONFIGS\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/anna/Desktop/Diploma/Learning/Sources/')\n",
    "\n",
    "\n",
    "from callbacks_2classes_x10 import plot_confusion_matrix\n",
    "from torch.nn import functional as F\n",
    "from callbacks_2classes_x10 import get_true_classes\n",
    "from callbacks_2classes_x10 import get_predicted_classes\n",
    "from callbacks_2classes_x10 import get_classes_probs\n",
    "from callbacks_2classes_x10 import callback\n",
    "from data_tools import CatsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4bde5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "labels_map_2cl = {\n",
    "    \"NotCat\": 0,\n",
    "    \"Cat\": 1,\n",
    "}\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = CatsDataset('train_paths.txt', transform = transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "val_dataset = CatsDataset('val_paths.txt', transform = transform)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7e6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"attention_data\", exist_ok=True)\n",
    "if not os.path.isfile(\"attention_data/ilsvrc2012_wordnet_lemmas.txt\"):\n",
    "    urlretrieve(\"https://storage.googleapis.com/bit_models/ilsvrc2012_wordnet_lemmas.txt\", \"attention_data/ilsvrc2012_wordnet_lemmas.txt\")\n",
    "if not os.path.isfile(\"attention_data/ViT-B_16-224.npz\"):\n",
    "    urlretrieve(\"https://storage.googleapis.com/vit_models/imagenet21k+imagenet2012/ViT-B_16-224.npz\", \"attention_data/ViT-B_16-224.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43e8246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Model\n",
    "config = CONFIGS['ViT-B_16']\n",
    "model = VisionTransformer(config, num_classes=1000, zero_head=False, img_size=224, vis=True)\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4370d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.head = nn.Linear(768, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c4a6e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_225551/62302592.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "model.to(device)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25d6948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"../../Logits/ViT_B_16_cats_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a99670f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(logdir)\n",
    "vit_callback = callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3538afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"../../Logits/SavedNN/Saved_ViT_L_16_pets/\" + str(6)))\n",
    "# model.to(device)\n",
    "# None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b8c9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = torch.from_numpy(np.array([0.5])).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2f1e2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm_notebook' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_312803/680833751.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# loop over the dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvit_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm_notebook' is not defined"
     ]
    }
   ],
   "source": [
    "epochs_num = 15\n",
    "\n",
    "for epoch in tqdm_notebook(range(epochs_num), desc='epochs'):  # loop over the dataset multiple times\n",
    "    \n",
    "    vit_callback.on_epoch_begin(epoch) \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    classes = []\n",
    "    true_classes= []\n",
    "    \n",
    "#     if epoch == 6:\n",
    "#         optimizer = optim.Adam(model.parameters(), lr=1e-5, betas=(0.9, 0.999))\n",
    "\n",
    "    for data in tqdm_notebook(train_dataloader, desc='one epoch training'):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        true_classes.append(labels.cpu().detach().numpy().astype(int))\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)[0]\n",
    "        if outputs.shape > torch.Size([1]):\n",
    "            outputs = outputs.squeeze()\n",
    "        if outputs.shape < torch.Size([1]):\n",
    "                outputs = outputs.unsqueeze(0)\n",
    "        \n",
    "        # СИГМОИДА И ГРАНИЦА\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        probs = probs.cpu().detach().numpy().astype(float)\n",
    "        classes.append(probs)\n",
    "        \n",
    "        # print(outputs.shape(), labels.shape())\n",
    "        outputs = outputs.to(device)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    running_loss /= len(true_classes)\n",
    "    \n",
    "    val_classes = []\n",
    "    val_true_classes = []\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    for data in tqdm_notebook(val_dataloader, desc='validation'):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        val_inputs, val_labels = data\n",
    "        val_true_classes.append(val_labels.cpu().detach().numpy().astype(int))\n",
    "        val_inputs = val_inputs.to(device)\n",
    "        val_labels = val_labels.to(device)\n",
    "    \n",
    "        # forward \n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(val_inputs)[0]\n",
    "            if val_outputs.shape > torch.Size([1]):\n",
    "                val_outputs = val_outputs.squeeze()\n",
    "            if val_outputs.shape < torch.Size([1]):\n",
    "                val_outputs = val_outputs.unsqueeze(0)\n",
    "            loss = criterion(val_outputs, val_labels.float())\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "        val_probs = torch.sigmoid(val_outputs)\n",
    "        val_probs = val_probs.cpu().detach().numpy().astype(float)\n",
    "        val_classes.append(val_probs) \n",
    "        \n",
    "    val_loss /= len(val_true_classes)\n",
    "\n",
    "    vit_callback.on_epoch_end(true_classes, classes, val_true_classes, val_classes,\n",
    "                          [\"NotCat\", \"Cat\"],\n",
    "                          running_loss, val_loss, writer)\n",
    "    \n",
    "    torch.save(model.state_dict(), \"../../Logits/SavedNN/Saved_ViT_B_16_cats/\" + str(epoch))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1371e06b",
   "metadata": {},
   "source": [
    "## Best Result - 2 or 4 epoch - ViT_B_32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c368e959",
   "metadata": {},
   "source": [
    "## Best Result - 6 epoch - ViT_B_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c52fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
