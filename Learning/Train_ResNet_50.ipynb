{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28bb8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mimetypes\n",
    "import fnmatch\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from progress.bar import IncrementalBar\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import io\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from datetime import datetime, date, time\n",
    "from PIL import Image\n",
    "import itertools \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.models as models\n",
    "\n",
    "from Sources.callbacks import plot_confusion_matrix\n",
    "from Sources.CoAtNet import CoAtNet\n",
    "from torch.nn import functional as F\n",
    "from Sources.callbacks import get_true_classes\n",
    "from Sources.callbacks import get_predicted_classes\n",
    "from Sources.callbacks import get_classes_probs\n",
    "from Sources.callbacks import callback\n",
    "from Sources.data_tools import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b839abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "labels_map = {\n",
    "    \"Benign\": 0,\n",
    "    \"InSitu\": 1,\n",
    "    \"Invasive\": 2,\n",
    "}\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = ImageDataset('../Data/burnasyan_Br.csv', 'train_paths.txt', transform = transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "train_features = train_features.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "\n",
    "val_dataset = ImageDataset('../Data/burnasyan_Br.csv', 'val_paths.txt', transform = transform)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "val_features, val_labels = next(iter(val_dataloader))\n",
    "val_features = val_features.to(device)\n",
    "val_labels = val_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9192e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnet50(pretrained=False)\n",
    "net.fc = nn.Linear(512, 3)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "net.apply(init_weights)\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f0aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"../Logits/ResNet_50_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = SummaryWriter(logdir)\n",
    "res_callback = callback()\n",
    "weight = torch.tensor([0.33, 0.03, 0.63])\n",
    "weight = weight.pow(-1)\n",
    "weight = weight.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weight, reduction='sum')\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-5, momentum=0.9)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=1e-5, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b8c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_num = 300\n",
    "\n",
    "for epoch in tqdm_notebook(range(epochs_num), desc='epochs'):  # loop over the dataset multiple times\n",
    "    \n",
    "    res_callback.on_epoch_begin(epoch) \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    classes = []\n",
    "    true_classes= []\n",
    "\n",
    "    for data in tqdm_notebook(train_dataloader, desc='one epoch training'):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        true_classes.append(labels)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        classes.append(nn.Softmax(dim=1)(outputs))\n",
    "        outputs = outputs.to(device)\n",
    "        # print(outputs.shape(), labels.shape())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    running_loss /= len(true_classes)\n",
    "    \n",
    "    val_classes = []\n",
    "    val_true_classes = []\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    for data in tqdm_notebook(val_dataloader, desc='validation'):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        val_inputs, val_labels = data\n",
    "        val_true_classes.append(val_labels)\n",
    "        val_inputs = val_inputs.to(device)\n",
    "        val_labels = val_labels.to(device)\n",
    "    \n",
    "        # forward \n",
    "        with torch.no_grad():\n",
    "            val_outputs = net(val_inputs)\n",
    "            loss = criterion(val_outputs, val_labels)\n",
    "            val_loss += loss.item()\n",
    "        val_classes.append(nn.Softmax(dim=1)(val_outputs))\n",
    "        \n",
    "    val_loss /= len(val_true_classes)\n",
    "\n",
    "    res_callback.on_epoch_end(true_classes, classes, val_true_classes, val_classes,\n",
    "                          [\"Benign\", \"InSitu\", \"Invasive\"],\n",
    "                          running_loss, val_loss, writer)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        torch.save(net.state_dict(), \"../Logits/SavedNN/Saved_ResNet/\" + str(epoch))\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
