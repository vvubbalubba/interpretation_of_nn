{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f5717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import io\n",
    "import os\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from Sources.ViT.models.modeling import VisionTransformer, CONFIGS\n",
    "\n",
    "from Sources.callbacks import plot_confusion_matrix\n",
    "from Sources.CoAtNet import CoAtNet\n",
    "from torch.nn import functional as F\n",
    "from Sources.callbacks import get_true_classes\n",
    "from Sources.callbacks import get_predicted_classes\n",
    "from Sources.callbacks import get_classes_probs\n",
    "from Sources.callbacks import callback\n",
    "from Sources.data_tools import ImageDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b44ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mimetypes\n",
    "import fnmatch\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from progress.bar import IncrementalBar\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import io\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from datetime import datetime, date, time\n",
    "from PIL import Image\n",
    "import itertools \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "labels_map = {\n",
    "    \"Benign\": 0,\n",
    "    \"InSitu\": 1,\n",
    "    \"Invasive\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Model\n",
    "config = CONFIGS[\"ViT-B_16\"]\n",
    "model = VisionTransformer(config, num_classes=1000, zero_head=False, img_size=224, vis=True)\n",
    "model.head = nn.Linear(768, 3)\n",
    "model.load_state_dict(torch.load(\"../Logits/SavedNN/Saved_ViT/\" + str(150)))\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057942ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_for_maps = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "dataset = ImageDataset('../Data/burnasyan_Br.csv', 'val_paths.txt', transform = transform_for_maps)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "features, labels = next(iter(dataloader))\n",
    "print(f\"Feature batch shape: {features.size()}\")\n",
    "print(f\"Labels batch shape: {len(labels)}\")\n",
    "img = features[0].squeeze().permute(1, 2, 0).int()\n",
    "print(img.shape)\n",
    "label = labels[0]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "im = features[0]\n",
    "x = transform(im)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaeaf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sources.ViT_baselines.ViT_LRP import vit_base_patch16_224 as vit_LRP\n",
    "from Sources.ViT_baselines.ViT_explanation_generator import LRP\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# create heatmap from mask on image\n",
    "def show_cam_on_image(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    return cam\n",
    "\n",
    "# initialize ViT pretrained\n",
    "model = vit_LRP(pretrained=True).cuda()\n",
    "model.eval()\n",
    "attribution_generator = LRP(model)\n",
    "\n",
    "def generate_visualization(original_image, class_index=None):\n",
    "    transformer_attribution = attribution_generator.generate_LRP(original_image.unsqueeze(0).cuda(), method=\"transformer_attribution\", index=class_index).detach()\n",
    "    transformer_attribution = transformer_attribution.reshape(1, 1, 14, 14)\n",
    "    transformer_attribution = torch.nn.functional.interpolate(transformer_attribution, scale_factor=16, mode='bilinear')\n",
    "    transformer_attribution = transformer_attribution.reshape(224, 224).cuda().data.cpu().numpy()\n",
    "    transformer_attribution = (transformer_attribution - transformer_attribution.min()) / (transformer_attribution.max() - transformer_attribution.min())\n",
    "    image_transformer_attribution = original_image.permute(1, 2, 0).data.cpu().numpy()\n",
    "    image_transformer_attribution = (image_transformer_attribution - image_transformer_attribution.min()) / (image_transformer_attribution.max() - image_transformer_attribution.min())\n",
    "    vis = show_cam_on_image(image_transformer_attribution, transformer_attribution)\n",
    "    vis =  np.uint8(255 * vis)\n",
    "    vis = cv2.cvtColor(np.array(vis), cv2.COLOR_RGB2BGR)\n",
    "    return vis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45938f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('samples/catdog.png')\n",
    "dog_cat_image = transform(image)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "axs[0].imshow(image);\n",
    "axs[0].axis('off');\n",
    "\n",
    "output = model(dog_cat_image.unsqueeze(0).cuda())\n",
    "\n",
    "# cat - the predicted class\n",
    "cat = generate_visualization(dog_cat_image)\n",
    "\n",
    "# dog \n",
    "# generate visualization for class 243: 'bull mastiff'\n",
    "dog = generate_visualization(dog_cat_image, class_index=243)\n",
    "\n",
    "\n",
    "axs[1].imshow(cat);\n",
    "axs[1].axis('off');\n",
    "axs[2].imshow(dog);\n",
    "axs[2].axis('off');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
